{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb354baf",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/router.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239412-lesson-5-router)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce6fff79-25b5-4884-8aaa-e3ebb7ddd549",
   "metadata": {},
   "source": [
    "# Router\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a graph that uses `messages` as state and a chat model with bound tools.\n",
    "\n",
    "We saw that the graph can:\n",
    "\n",
    "* Return a tool call\n",
    "* Return a natural language response\n",
    "\n",
    "## Goals\n",
    "\n",
    "We can think of this as a router, where the chat model routes between a direct response or a tool call based upon the user input.\n",
    "\n",
    "This is a simple example of an agent, where the LLM is directing the control flow either by calling a tool or just responding directly. \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.09 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbac6543c3d4df239a4ed1_router1.png)\n",
    "\n",
    "Let's extend our graph to work with either output! \n",
    "\n",
    "For this, we can use two ideas:\n",
    "\n",
    "(1) Add a node that will call our tool.\n",
    "\n",
    "(2) Add a conditional edge that will look at the chat model output, and route to our tool calling node or simply end if no tool call is performed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb4fc6e-7c85-4fc8-a4a9-0c7a527c4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885e92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ba4df4-3045-49b1-9299-ced1fce14d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77555a2",
   "metadata": {},
   "source": [
    " We use the [built-in `ToolNode`](https://langchain-ai.github.io/langgraph/reference/prebuilt/?h=tools+condition#toolnode) and simply pass a list of our tools to initialize it. \n",
    " \n",
    " We use the [built-in `tools_condition`](https://langchain-ai.github.io/langgraph/reference/prebuilt/?h=tools+condition#tools_condition) as our conditional edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6fde4e-cceb-4426-b770-97ee4b41e9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([multiply]))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b608c5-0c15-4fb7-aa24-80ce5774fb85",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m      2\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mHello, what is 2 multiplied by 2?\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m messages = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      5\u001b[39m     m.pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtool_calling_llm\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtool_calling_llm\u001b[39m(state: MessagesState):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:995\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    993\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain-academy/.venv/lib/python3.13/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "During task with name 'tool_calling_llm' and id '7e1e7ba3-aa24-9d3d-1634-6876131b8bed'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Hello, what is 2 multiplied by 2?\")]\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34708377-16b6-4474-9e23-71890c1fb36e",
   "metadata": {},
   "source": [
    "Now, we can see that the graph runs the tool!\n",
    "\n",
    "It responds with a `ToolMessage`. \n",
    "\n",
    "## LangGraph Studio\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "-  API: http://127.0.0.1:2024\n",
    "-  Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "-  API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "Load the `router` in Studio, which uses `module-1/studio/router.py` set in `module-1/studio/langgraph.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43782c33-0f41-47f2-ae38-ddb2cd4ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94928b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
